from typing import TypedDict, List, Literal, Optional, Annotated

# æ–°å¢æ—¥å¿—è®°å½•å™¨é…ç½®ï¼ˆæ‰€æœ‰èŠ‚ç‚¹é€šç”¨ï¼‰
import logging

logging.basicConfig(
    level=logging.DEBUG,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.StreamHandler(),  # æ§åˆ¶å°è¾“å‡º
        logging.FileHandler("agent_workflow.log", encoding='utf-8')  # å…³é”®ä¿®æ”¹
    ]
)
logger = logging.getLogger(__name__)

class AgentState(TypedDict):
    input: str                   # åŸå§‹ç”¨æˆ·è¾“å…¥
    clarified_input: str         # ç”¨æˆ·è¡¥å……åçš„å®Œæ•´è¾“å…¥
    plan_type: Optional[Literal["query", "analysis"]]  # ä»»åŠ¡ç±»å‹
    task_list: List[str]          # ä»»åŠ¡æ­¥éª¤åˆ—è¡¨
    current_step: int             # å½“å‰æ‰§è¡Œæ­¥éª¤ç´¢å¼•
    query_result: str             # æŸ¥è¯¢ç»“æœ
    analysis_result: str          # åˆ†æç»“æœ
    report: str                   # æœ€ç»ˆæŠ¥å‘Š
    next_node: str                # ä¸‹ä¸€èŠ‚ç‚¹è·¯ç”±æ ‡è¯†
    missing_info: str             # ç¼ºå¤±ä¿¡æ¯æç¤º


from langgraph.graph import StateGraph, END
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from pydantic import BaseModel
import os


# 1. è§„åˆ’èŠ‚ç‚¹ - åŠ¨æ€ç”Ÿæˆä»»åŠ¡åˆ—è¡¨
def planner_node(state: AgentState):
    logger.info(f"ğŸš€ è¿›å…¥è§„åˆ’èŠ‚ç‚¹")

    # LLMä»»åŠ¡è§„åˆ’æç¤ºè¯ï¼ˆå«æ¨¡ç³Šæ£€æµ‹ï¼‰
    class PlanResponse(BaseModel):
        plan_type: Literal["query", "analysis", "ambiguous"]
        task_list: List[str] = []
        missing_info: str = ""

    planner_prompt = ChatPromptTemplate.from_template("""
    æ ¹æ®ç”¨æˆ·è¾“å…¥ã€Œ{input}ã€è¿›è¡Œä»»åŠ¡è§„åˆ’ï¼š
    1. è‹¥åŒ…å«æ˜ç¡®æŒ‡æ ‡/æ—¶é—´/ç»´åº¦ â†’ è¿”å›ä»»åŠ¡è®¡åˆ’ï¼Œplan_type ä¸º "query" æˆ– "analysis"ï¼Œå¹¶åˆ—å‡ºä»»åŠ¡æ­¥éª¤
    2. å¦åˆ™ â†’ è¿”å›ç¼ºå¤±ä¿¡æ¯å¼•å¯¼è¯­ï¼Œplan_type ä¸º "ambiguous"ï¼Œå¹¶åœ¨ missing_info å­—æ®µè¯´æ˜éœ€è¡¥å……å†…å®¹
    è¾“å‡ºæ ¼å¼ï¼šè¯·ç”¨JSONæ ¼å¼è¾“å‡º, {{"plan_type":"query", "task_list": ["query", "analysis", "report"], "missing_info": ""}}""")

    # æ‰§è¡Œè§„åˆ’
    llm = ChatOpenAI(
        model="qwen-plus",  # DeepSeekçš„å¯¹è¯æ¨¡å‹
        temperature=0,
        api_key=os.getenv("DASHSCOPE_API_KEY"),
        base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
    )
    planner_chain = planner_prompt | llm.with_structured_output(PlanResponse)
    response = planner_chain.invoke({"input": state.get("clarified_input") or state.get("input")})

    logger.debug(f"è§„åˆ’ç»“æœ: plan_type={response.plan_type}, tasks={len(response.task_list)}")

    # åŠ¨æ€è·¯ç”±è®¾ç½®
    if response.plan_type == "ambiguous":
        return {"missing_info": response.missing_info, "next_node": "clarify"}
    else:
        return {
            "plan_type": response.plan_type,
            "task_list": response.task_list,
            "current_step": 0,
            "next_node": "dispatch"  # è¿›å…¥ä»»åŠ¡åˆ†å‘
        }


# 2. å¼•å¯¼èŠ‚ç‚¹ - è·å–ç”¨æˆ·è¡¥å……ä¿¡æ¯
def clarify_node(state: AgentState):
    missing_info = state.get("missing_info", "è¯·æä¾›æ›´å¤šä¿¡æ¯")
    logger.warning(f"âš ï¸ éœ€è¦ç”¨æˆ·è¡¥å……ä¿¡æ¯: {missing_info}")

    # äº¤äº’å¼è·å–ç”¨æˆ·è¾“å…¥
    while True:
        try:
            user_input = input(">>> è¯·è¡¥å……ä¿¡æ¯: ")
            if not user_input.strip():
                raise ValueError("è¾“å…¥ä¸èƒ½ä¸ºç©º")
            break
        except Exception as e:
            logger.error(f"è¾“å…¥é”™è¯¯: {str(e)}")

    logger.info(f"ğŸ“ ç”¨æˆ·è¡¥å……å†…å®¹: {user_input[:30]}...")
    return {
        "clarified_input": f"{state.get('input')} {user_input}".strip(),
        "next_node": "planner"
    }


# 3. ä»»åŠ¡åˆ†å‘èŠ‚ç‚¹ - åŠ¨æ€è·¯ç”±
def dispatch_node(state: AgentState):
    current_step = state["current_step"]
    total_steps = len(state["task_list"])
    logger.info(f"ğŸ”„ ä»»åŠ¡åˆ†å‘ | æ­¥éª¤ {current_step+1}/{total_steps}")

    if state["current_step"] >= len(state["task_list"]):
        return {"next_node": "final_step"}  # ä»»åŠ¡å®Œæˆ

    current_task = state["task_list"][state["current_step"]]

    logger.debug(f"è·¯ç”±å†³ç­–: {current_task}")

    # æ ¹æ®ä»»åŠ¡æè¿°è·¯ç”±
    if "query" == current_task:
        return {"next_node": "query"}
    elif "analysis" == current_task:
        return {"next_node": "analysis"}
    elif "report" == current_task:
        return {"next_node": "report"}
    else:
        return {"next_node": "fallback"}  # å¼‚å¸¸å¤„ç†


# 4. æŸ¥è¯¢èŠ‚ç‚¹ - æ•°æ®è·å–
def query_node(state: AgentState):

    task_desc = state["task_list"][state["current_step"]]
    logger.info(f"ğŸ” æ‰§è¡ŒæŸ¥è¯¢ä»»åŠ¡: {task_desc}")

    # å®é™…åº”æ¥å…¥æ•°æ®åº“/API
    mock_data = {"é”€å”®é¢": "120ä¸‡", "ç”¨æˆ·é‡": "45ä¸‡ DAU"}
    result = next((v for k, v in mock_data.items() if k in task_desc), "æœªæ‰¾åˆ°æ•°æ®")

    return {
        "query_result": result,
        "current_step": state["current_step"] + 1,  # æ­¥éª¤ç´¢å¼•+1
        "next_node": "dispatch"  # è¿”å›åˆ†å‘èŠ‚ç‚¹
    }


# 5. åˆ†æèŠ‚ç‚¹ - æ•°æ®å¤„ç†
def analysis_node(state: AgentState):
    task_desc = state["task_list"][state["current_step"]]
    logger.info(f"ğŸ“Š æ‰§è¡Œåˆ†æä»»åŠ¡: {task_desc}")

    # å®é™…åº”æ¥å…¥åˆ†æåº“
    analysis = f"åŸºäºã€Œ{state['query_result']}ã€çš„åˆ†æï¼š\n"
    analysis += "1. å‘ç°å¼‚å¸¸æ³¢åŠ¨ç‚¹\n2. å…³é”®å› ç´ ç›¸å…³ç³»æ•°0.85"

    return {
        "analysis_result": analysis,
        "current_step": state["current_step"] + 1,
        "next_node": "dispatch"
    }


# 6. æŠ¥å‘ŠèŠ‚ç‚¹ - ç»“æœç”Ÿæˆ
def report_node(state: AgentState):
    logger.info("ğŸ“ ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š")
    report = f"# åˆ†ææŠ¥å‘Š\n## å…³é”®æ•°æ®\n{state['query_result']}\n"
    report += f"## æ·±åº¦æ´å¯Ÿ\n{state['analysis_result']}\n"
    report += "## å»ºè®®\n1. ä¼˜åŒ–äº§å“åŠŸèƒ½\n2. è°ƒæ•´è¥é”€ç­–ç•¥"

    return {
        "report": report,
        "current_step": state["current_step"] + 1,
        "next_node": "dispatch"
    }

# ç»“æŸèŠ‚ç‚¹
def final_node(state: AgentState):
    print("æµç¨‹ç»ˆæ­¢")
    return {
        "next_node": "final_step"
    }

# ç»“æŸèŠ‚ç‚¹
def fallback(state: AgentState):
    print("ä»»åŠ¡å¼‚å¸¸, è¯·æ£€æŸ¥è¾“å…¥æˆ–ä»»åŠ¡æè¿°")
    return {
        "next_node": "fallback"
    }

# 7. æ–°å¢å¯è§†åŒ–å‡½æ•°ï¼ˆè°ƒè¯•ç”¨ï¼‰
def visualize_workflow():
    """ç”Ÿæˆå·¥ä½œæµMermaidå›¾"""
    mermaid = """
    graph TD
        planner[è§„åˆ’èŠ‚ç‚¹] -->|éœ€è¡¥å……| clarify(äº¤äº’èŠ‚ç‚¹)
        planner -->|ä»»åŠ¡å°±ç»ª| dispatch[åˆ†å‘èŠ‚ç‚¹]
        dispatch -->|æŸ¥è¯¢| query[æŸ¥è¯¢èŠ‚ç‚¹]
        dispatch -->|åˆ†æ| analysis[åˆ†æèŠ‚ç‚¹]
        dispatch -->|æŠ¥å‘Š| report[æŠ¥å‘ŠèŠ‚ç‚¹]
        dispatch -->|å®Œæˆ| final_step[ç»“æŸèŠ‚ç‚¹]
        query --> dispatch
        analysis --> dispatch
        report --> dispatch
        clarify --> planner
        final_step --> END([ç»“æŸ])
    """
    logger.debug("å·¥ä½œæµç»“æ„:\n" + mermaid)
    return mermaid

# åˆå§‹åŒ–çŠ¶æ€å›¾
workflow = StateGraph(AgentState)

# æ³¨å†ŒèŠ‚ç‚¹
workflow.add_node("planner", planner_node)
workflow.add_node("clarify", clarify_node)
workflow.add_node("dispatch", dispatch_node)
workflow.add_node("query", query_node)
workflow.add_node("analysis", analysis_node)
workflow.add_node("report", report_node)
workflow.add_node("fallback", fallback)
workflow.add_node("final_step", final_node)  # æ·»åŠ çœŸå®èŠ‚ç‚¹


# è®¾ç½®å…¥å£
workflow.set_entry_point("planner")

# æ¡ä»¶è·¯ç”±è§„åˆ™
workflow.add_conditional_edges(
    "planner",
    lambda s: s.get("next_node", "dispatch"),
    {"dispatch": "dispatch", "clarify": "clarify"}
)

workflow.add_conditional_edges(
    "dispatch",
    lambda s: s["next_node"],
    {
        "query": "query",
        "analysis": "analysis",
        "report": "report",
        "final_step": "final_step",
        "fallback": "clarify",
    }
)

# å›ºå®šæµè½¬è·¯å¾„
workflow.add_edge("clarify", "planner")
workflow.add_edge("query", "dispatch")
workflow.add_edge("analysis", "dispatch")
workflow.add_edge("report", "dispatch")
workflow.add_edge("final_step", END)         # è¿æ¥åˆ°ENDæ ‡è¯†ç¬¦

# ç¼–è¯‘å·¥ä½œæµ
app = workflow.compile()


def run_workflow(question):
    """äº¤äº’å¼å·¥ä½œæµæ‰§è¡Œå™¨"""
    # è·å–ç”¨æˆ·åˆå§‹è¾“å…¥
    question = input("ğŸ’¬ è¯·è¾“å…¥æ‚¨çš„é—®é¢˜: ")
    logger.info(f"ğŸš© å¯åŠ¨å·¥ä½œæµ | åˆå§‹é—®é¢˜: {question}")

    # å¯è§†åŒ–å·¥ä½œæµï¼ˆå¯é€‰ï¼‰
    visualize_workflow()

    # åˆå§‹åŒ–çŠ¶æ€
    state = {"input": question}

    # æ‰§è¡Œæµç¨‹
    while "next_node" not in state or state["next_node"] != "final_step":
        state = app.invoke(state)

    # è¾“å‡ºç»“æœ
    if state["plan_type"] == "query":
        print(f"ğŸ“Š æŸ¥è¯¢ç»“æœ: {state['query_result']}")
    else:
        print(f"ğŸ“ˆ åˆ†ææŠ¥å‘Š:\n{state['report']}")


# æµ‹è¯•æ‰§è¡Œ
run_workflow("åˆ†æQ3é”€å”®é¢ä¸‹é™åŸå› ")